{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from regression_class import RedditRegression as RR\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"09_04_2024\"\n",
    "RESULTS_DIR_PREFIX = f\"regression_outputs/{DATE}_\"\n",
    "RESULTS_DIR_SUFFIX = \"/results\"\n",
    "OUT_DIR_SUFFIX = \"/outputs\"\n",
    "RUN_NAMES = [\"c7_m7\", \"c7_m14\", \"c14_m7\"]\n",
    "LOGFILE = f\"{RESULTS_DIR_PREFIX}_communal_processing\"\n",
    "\n",
    "\n",
    "OUT_DIR_COMBINED = f\"regression_outputs/{DATE}_outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filepaths = []\n",
    "for run_name in RUN_NAMES:\n",
    "    results_dir = RESULTS_DIR_PREFIX + run_name + RESULTS_DIR_SUFFIX\n",
    "\n",
    "    filepaths = [f\"{results_dir}/{x}\" for x in os.listdir(results_dir)]\n",
    "    all_filepaths += filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_thread_counts_dict = {\n",
    "    'subreddit': [],\n",
    "    'model window': [],\n",
    "    'collection window': [],\n",
    "    'thread size threshold': [],\n",
    "    'cal modelled threads': [],\n",
    "    'val modelled threads': [],\n",
    "    'cal author threshold removed threads': [],\n",
    "    'val author threshold removed threads': [],\n",
    "    'cal thread size removed threads': [],\n",
    "    'val thread size removed threads': [],\n",
    "}\n",
    "\n",
    "lookup_dict = {\n",
    "    'cal modelled threads': ('cal', 'modelled_threads'),\n",
    "    'val modelled threads': ('val', 'modelled_threads'),\n",
    "    'cal author threshold removed threads': ('cal', 'author_all_activity_count_removed_threads'),\n",
    "    'val author threshold removed threads': ('val', 'author_all_activity_count_removed_threads'),\n",
    "    'cal thread size removed threads': ('cal', 'thread_size_removed_threads'),\n",
    "    'val thread size removed threads': ('val', 'thread_size_removed_threads'),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in all_filepaths:\n",
    "    regres = pickle.load(open(filepath, 'rb'))\n",
    "    if regres.regression_params['regression_type'] != 'mnlogit':\n",
    "        modelled_thread_counts_dict['subreddit'].append(regres.regression_params['name'])\n",
    "        modelled_thread_counts_dict['model window'].append(regres.regression_params['model_window'])\n",
    "        modelled_thread_counts_dict['collection window'].append(regres.regression_params['collection_window'])\n",
    "        if 'thread_size' in regres.regression_params['thresholds']:\n",
    "            thread_size_threshold = True\n",
    "            modelled_thread_counts_dict['thread size threshold'].append(regres.regression_params['thresholds']['thread_size'])\n",
    "        else:\n",
    "            thread_size_threshold = False\n",
    "            modelled_thread_counts_dict['thread size threshold'].append(0)\n",
    "        regres.get_num_threads_modelled()\n",
    "        for key in lookup_dict:\n",
    "            i = lookup_dict[key][0]\n",
    "            j = lookup_dict[key][1]\n",
    "            if (j == 'thread_size_removed_threads') & (thread_size_threshold == False):\n",
    "                modelled_thread_counts_dict[key].append(0)\n",
    "            else:\n",
    "                modelled_thread_counts_dict[key].append(regres.num_threads_modelled.loc[i,j])\n",
    "                \n",
    "    \n",
    "    del regres\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_count_df = pd.DataFrame.from_dict(modelled_thread_counts_dict, orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_output = thread_count_df.sort_values(by=['subreddit', 'model window', 'collection window', 'thread size threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('regression_outputs/09042024_data_sizes.xlsx') as writer:\n",
    "    to_output.to_excel(writer, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
