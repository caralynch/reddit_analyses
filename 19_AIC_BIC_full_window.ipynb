{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from reddit_dataclass import RedditData as reddit\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import scipy.stats as scpstat\n",
    "import matplotlib.dates as dates\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from itertools import groupby\n",
    "import os\n",
    "\n",
    "\n",
    "# for feature selection\n",
    "from sklearn import linear_model\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_COLS = ['activity_ratio', 'mean_author_sentiment_magnitude',\n",
    "              'mean_author_sentiment_sign', 'hour', 'sentiment_sign',\n",
    "              'sentiment_magnitude', 'num_dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'regression_infile': \"regression_thread_data.p\",\n",
    "    'thread_infile': 'clean_5_thread_data.p',\n",
    "    'collection window': 7,\n",
    "    'model window': 7,\n",
    "    'step': 7,\n",
    "    'performance scoring method': 'roc_auc',\n",
    "    'x_cols': X_COLS,\n",
    "    'y_col': 'success'\n",
    "}\n",
    "\n",
    "outdir = 'feature_selection_1'\n",
    "regression_params_outfile = 'regression_params.xlsx'\n",
    "regression_metrics_outfile = 'regression_metrics.xlsx'\n",
    "pickle_outfile = 'regression_data.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = pd.DataFrame.from_dict(params, orient='index').rename(columns={0: 'input'})\n",
    "params_df.index.name = 'param'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(timestamp):\n",
    "    return timestamp.date()\n",
    "\n",
    "def get_score(row):\n",
    "    if row.thread_id == row.id:\n",
    "        return row.subject_sentiment_score\n",
    "    else:\n",
    "        return row.body_sentiment_score\n",
    "    \n",
    "def float_seconds(time_row):\n",
    "    hours = time_row.hour\n",
    "    minutes = time_row.minute\n",
    "    seconds = time_row.second\n",
    "    return hours*60*60 + minutes*60 + seconds\n",
    "\n",
    "def get_dayofweek(timestamp):\n",
    "    return timestamp.dayofweek\n",
    "\n",
    "def get_hour(timestamp):\n",
    "    return timestamp.hour\n",
    "\n",
    "column_functions = {\n",
    "    'time_in_secs': float_seconds,\n",
    "    'num_dayofweek': get_dayofweek,\n",
    "    'hour': get_hour\n",
    "}\n",
    "\n",
    "def get_thread_collection_data(thread_data, date_array, date_index, collection_window=params['collection window']):\n",
    "\n",
    "    # get collection dates\n",
    "    collection_dates = date_array[date_index:date_index+collection_window]\n",
    "\n",
    "    # get thread data in collection dates\n",
    "    thread_collection_data = thread_data[thread_data.timestamp.apply(get_date).isin(collection_dates)]\n",
    "\n",
    "    # separate by activity\n",
    "    thread_activity = {\n",
    "        'all_activity': thread_collection_data,\n",
    "        'post': thread_collection_data[thread_collection_data.thread_id == thread_collection_data.id],\n",
    "        'comment': thread_collection_data[thread_collection_data.thread_id != thread_collection_data.id]\n",
    "    }\n",
    "\n",
    "    return thread_activity\n",
    "\n",
    "def get_regression_model_data(regression_data,\n",
    "    date_array, date_index,\n",
    "    collection_window=params['collection window'],\n",
    "    model_window=params['model window']):\n",
    "\n",
    "    model_dates = date_array[\n",
    "        date_index + collection_window : date_index + collection_window + model_window\n",
    "        ]\n",
    "    \n",
    "    return regression_data[regression_data.timestamp.apply(get_date).isin(model_dates)]\n",
    "\n",
    "\n",
    "def get_sm_models(x_list_dict, y=params['y_col']):\n",
    "    models = {}\n",
    "    for feat_num in x_list_dict:\n",
    "        models[feat_num] = f\"{y} ~\"\n",
    "        for i, feat_name in enumerate(x_list_dict[feat_num]):\n",
    "            if i != 0:\n",
    "                models[feat_num] += ' +'\n",
    "            models[feat_num] += f' {feat_name}'\n",
    "    return models\n",
    "\n",
    "def get_author_activity_counts_and_sentiment_means(collection_thread_data_dict):\n",
    "    started = False\n",
    "    for key in collection_thread_data_dict:\n",
    "        author_activity_count = collection_thread_data_dict[key][['author', 'id']].groupby('author').count().rename(columns={'id': f'author_{key}_count'})\n",
    "        if not started:\n",
    "            author_activity = author_activity_count\n",
    "            started = True\n",
    "        else:\n",
    "            author_activity = pd.concat((author_activity, author_activity_count), axis=1).fillna(0).astype(int)\n",
    "        #author_mean_sentiment[key] = collection_thread_data_dict[key][['author', 'sentiment_score']].groupby('author').mean().rename(columns={'sentiment_score': f'author_{key}_mean_sentiment'})\n",
    "\n",
    "    author_activity['activity_ratio'] = (\n",
    "        (author_activity.author_comment_count - author_activity.author_post_count)/\n",
    "        author_activity.author_all_activity_count\n",
    "    )\n",
    "\n",
    "    author_mean_sentiment = collection_thread_data_dict['all_activity'][['author', 'sentiment_score']].groupby('author').mean().rename(columns={'sentiment_score': f'mean_author_sentiment'})\n",
    "\n",
    "    # combine to form author info df\n",
    "    return pd.concat((author_activity[['author_all_activity_count', 'activity_ratio']], author_mean_sentiment), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_data_by_time_period(relevant_thread_data, subreddit_regression_data, subreddit_FSS_metrics, date_array, date_index, period_counter):\n",
    "    # get thread data for collection time period\n",
    "    # as dict for activity breakdown\n",
    "    collection_thread_data_by_activity = get_thread_collection_data(relevant_thread_data, date_array, date_index)\n",
    "\n",
    "    # get activity counts and sentiment means\n",
    "    author_data = get_author_activity_counts_and_sentiment_means(collection_thread_data_by_activity)\n",
    "    \n",
    "    # get regression model data\n",
    "    regression_model_data = get_regression_model_data(subreddit_regression_data, date_array, date_index)\n",
    "    \n",
    "    # combine collected author info data from collection period with model data in model time period\n",
    "    regression_model_data = regression_model_data.merge(author_data.reset_index(), on='author')\n",
    "\n",
    "    # separate mean author sentiment into magnitude and sign\n",
    "    col = 'mean_author_sentiment'\n",
    "    regression_model_data[f'{col}_sign'] = np.sign(regression_model_data[col])\n",
    "    regression_model_data[f'{col}_magnitude'] = np.absolute(regression_model_data[col])\n",
    "\n",
    "    # make other required cols\n",
    "    for col in [x for x in column_functions if x in X_COLS]:\n",
    "        regression_model_data[col] = regression_model_data.timestamp.apply(column_functions[col])\n",
    "    \n",
    "    # RUN WHATEVER FUNCTION IS NEEDED\n",
    "    # get X lists for models to run (output from FSS)\n",
    "    x_mods_to_run = get_x_feats_to_run(subreddit_FSS_metrics, period_counter)\n",
    "\n",
    "    # make dict of statsmodels format models to run\n",
    "    sm_model_strings = get_sm_models(x_mods_to_run)\n",
    "\n",
    "    out_dict = {\n",
    "        'model_strings': sm_model_strings,\n",
    "        'data': regression_model_data\n",
    "        }\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regressions(relevant_thread_data, subreddit_regression_data, subreddit_FSS_metrics, date_array, date_index, period_counter):\n",
    "    regression_dict = get_regression_data_by_time_period(\n",
    "        relevant_thread_data, subreddit_regression_data,\n",
    "        subreddit_FSS_metrics,date_array, date_index, period_counter)\n",
    "    model_results = {}\n",
    "    param_dict = {}\n",
    "    for key in regression_dict['model_strings']:\n",
    "        print(f\"Model {key}\")\n",
    "        logit_mod = smf.logit(regression_dict['model_strings'][key], data=regression_dict['data']).fit()\n",
    "        model_results[key] = {}\n",
    "        model_results[key]['num_features'] = key\n",
    "        model_results[key]['model'] = regression_dict['model_strings'][key]\n",
    "        model_results[key]['aic'] = logit_mod.aic\n",
    "        model_results[key]['bic'] = logit_mod.bic\n",
    "    \n",
    "        param_dict[key] = pd.DataFrame(logit_mod.params).rename(columns={0: key})\n",
    "        \n",
    "        model_results[key]['auc'] = metrics.roc_auc_score(regression_dict['data'].success, logit_mod.predict())\n",
    "        \n",
    "    \n",
    "    model_results = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "\n",
    "    out_dict = {\n",
    "        'regression_params': param_dict,\n",
    "        'metrics': model_results\n",
    "    }\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AIC_BIC_by_time_period(subreddit_thread_data,\n",
    "                                subreddit_regression_data,\n",
    "                                collection_window=params['collection window'],\n",
    "                                model_window=params['model window'],\n",
    "                                step=params['step']\n",
    "                                ):\n",
    "\n",
    "    # get one col for sentiment score\n",
    "    subreddit_thread_data['sentiment_score'] = subreddit_thread_data.apply(get_score, axis = 1)\n",
    "\n",
    "    # only use wanted cols\n",
    "    relevant_thread_data = subreddit_thread_data[['thread_id', 'id', 'timestamp', 'author', 'sentiment_score']]\n",
    "    \n",
    "    # get array of dates in dataset\n",
    "    date_array = relevant_thread_data.timestamp.apply(get_date).unique()\n",
    "\n",
    "    # start time period counter (start on 1 as period 0 is collection data not modelled)\n",
    "    period_counter = 1\n",
    "\n",
    "    # get dict for info collection\n",
    "    regression_metrics = {}\n",
    "\n",
    "    # iterate through date array windows\n",
    "    for date_index in range(0, len(date_array) - (collection_window + model_window), step):\n",
    "        print(f\"Period {period_counter}\")\n",
    "\n",
    "        regression_metrics[period_counter] = run_regressions(\n",
    "            relevant_thread_data, subreddit_regression_data, subreddit_FSS_metrics, date_array, date_index, period_counter\n",
    "            )\n",
    "        \n",
    "        # add another week to counter\n",
    "        period_counter += 1\n",
    "    \n",
    "    return regression_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = pickle.load(open(params['regression_infile'], 'rb'))\n",
    "thread_df = pickle.load(open(params['thread_infile'], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_metrics = {}\n",
    "for subreddit in regression_df:\n",
    "    print(f\"{subreddit}\")\n",
    "    regression_metrics[subreddit] = get_AIC_BIC_by_time_period(\n",
    "        thread_df[subreddit],\n",
    "        regression_df[subreddit]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_feats_to_run(subreddit_FSS_metrics, period):\n",
    "    period_metrics = subreddit_FSS_metrics[subreddit_FSS_metrics.index == period].reset_index()\n",
    "    features = {}\n",
    "    i=1\n",
    "    for feature_tuple in period_metrics.feature_names:\n",
    "        features[i] = list(feature_tuple)\n",
    "        i += 1\n",
    "    return features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
