{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from regression_class import RedditRegression as RR\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'regression_outputs/18_12_2024_c14_m7/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(RESULTS_DIR)\n",
    "path_list = [f'{RESULTS_DIR}/{x}' for x in filenames if x.endswith('.p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelled_thread_counts_dict = {\n",
    "    'subreddit': [],\n",
    "    'model window': [],\n",
    "    'collection window': [],\n",
    "    'thread size threshold': [],\n",
    "    'cal modelled threads': [],\n",
    "    'val modelled threads': [],\n",
    "    'cal author threshold removed threads': [],\n",
    "    'val author threshold removed threads': [],\n",
    "    'cal thread size removed threads': [],\n",
    "    'val thread size removed threads': [],\n",
    "}\n",
    "\n",
    "lookup_dict = {\n",
    "    'cal modelled threads': ('cal', 'modelled_threads'),\n",
    "    'val modelled threads': ('val', 'modelled_threads'),\n",
    "    'cal author threshold removed threads': ('cal', 'author_all_activity_count_removed_threads'),\n",
    "    'val author threshold removed threads': ('val', 'author_all_activity_count_removed_threads'),\n",
    "    'cal thread size removed threads': ('cal', 'thread_size_removed_threads'),\n",
    "    'val thread size removed threads': ('val', 'thread_size_removed_threads'),\n",
    "}\n",
    "\n",
    "\n",
    "def get_modelled_thread_counts(regres):\n",
    "    if regres.regression_params['regression_type'] != 'mnlogit':\n",
    "        modelled_thread_counts_dict['subreddit'].append(regres.regression_params['name'])\n",
    "        modelled_thread_counts_dict['model window'].append(regres.regression_params['model_window'])\n",
    "        modelled_thread_counts_dict['collection window'].append(regres.regression_params['collection_window'])\n",
    "        if 'thread_size' in regres.regression_params['thresholds']:\n",
    "            thread_size_threshold = True\n",
    "            modelled_thread_counts_dict['thread size threshold'].append(regres.regression_params['thresholds']['thread_size'])\n",
    "        else:\n",
    "            thread_size_threshold = False\n",
    "            modelled_thread_counts_dict['thread size threshold'].append(0)\n",
    "        regres.get_num_threads_modelled()\n",
    "        for key in lookup_dict:\n",
    "            i = lookup_dict[key][0]\n",
    "            j = lookup_dict[key][1]\n",
    "            if (j == 'thread_size_removed_threads') & (thread_size_threshold == False):\n",
    "                modelled_thread_counts_dict[key].append(0)\n",
    "            else:\n",
    "                modelled_thread_counts_dict[key].append(regres.num_threads_modelled.loc[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metrics_for_plotting(result_pickle):\n",
    "    param_metrics = result_pickle.regression_params[\"metrics\"]\n",
    "    metric_cols = result_pickle.regression_metrics[\"metrics\"].columns\n",
    "    return [x for x in param_metrics if x != \"mnlogit_aucs\"], metric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 28\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "plt.rc('axes', titlelocation='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_map = {\n",
    "    'crypto': '(b) CryptoCurrency',\n",
    "    'conspiracy': '(a) Conspiracy',\n",
    "    'politics': '(c) politics'\n",
    "}\n",
    "ylabel_map = {\n",
    "    'r2': 'R-squared',\n",
    "    'auc': 'AUC',\n",
    "    'mnlogit_accuracy': 'Accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_list(feature_names:pd.Series):\n",
    "\n",
    "    feature_list = []\n",
    "    for i, feat_tuple in enumerate(feature_names):\n",
    "\n",
    "        if i == 0:\n",
    "            feature_list.append(feat_tuple[0])\n",
    "        else:\n",
    "            new_feature = [x for x in feat_tuple if x not in feature_list]\n",
    "            feature_list += new_feature\n",
    "\n",
    "\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## regression_outputs/18_12_2024_c14_m7/results/conspiracy_mnlogit.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/politics_mnlogit.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/conspiracy_logistic.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/politics_linear.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/crypto_logistic.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/crypto_mnlogit.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/crypto_linear.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/politics_logistic.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n",
      "## regression_outputs/18_12_2024_c14_m7/results/conspiracy_linear.p\n",
      " Reading in\n",
      " Outputting to excel\n",
      " Getting dates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load pickles\n",
    "dates = {}\n",
    "legend_fig = True\n",
    "features_dict = {'conspiracy': {}, 'crypto': {}, 'politics': {}}\n",
    "for filename in path_list:\n",
    "    print(f'## {filename}')\n",
    "    key = filename.split('/')[-1].removesuffix('.p')\n",
    "    print(\" Reading in\")\n",
    "    regres = pickle.load(open(f\"{filename}\", 'rb'))\n",
    "    print(\" Outputting to excel\")\n",
    "    regres.output_to_excel(f\"{RESULTS_DIR}/{key}.xlsx\")\n",
    "    print(\" Getting dates\")\n",
    "    date_array = regres.date_array\n",
    "    dates[key] = {'start': date_array.loc[0], 'end': date_array.iloc[-1], 'days': len(date_array)}\n",
    "\n",
    "    # get model threads count\n",
    "    get_modelled_thread_counts(regres)\n",
    "\n",
    "    # get FSS feature lists\n",
    "    name = regres.regression_params['name']\n",
    "    regtype = regres.regression_params['regression_type']\n",
    "    features_dict[name][f'{regtype}_feat'] = get_feature_list(\n",
    "        regres.FSS_metrics['metric_df'].feature_names\n",
    "    )\n",
    "    for colname in [\n",
    "        x for x in regres.regression_metrics['metrics'].columns if (\n",
    "            ('cal' in x) or ('val' in x)\n",
    "        )]:\n",
    "        features_dict[name][f\"{regtype}_{colname}\"] = list(regres.regression_metrics['metrics'][colname])\n",
    "    \n",
    "    # plot metrics\n",
    "    metric_list, metric_cols = find_metrics_for_plotting(regres)\n",
    "    for metric in metric_list:\n",
    "        metrics_to_plot = [x for x in metric_cols if metric in x]\n",
    "        if metric in ylabel_map:\n",
    "            ylabel = ylabel_map[metric]\n",
    "        else:\n",
    "            ylabel = metric\n",
    "        regres.plot_metrics_vs_features(\n",
    "            metrics_to_plot,\n",
    "            ylabel,\n",
    "            name=f\"{key}\",\n",
    "            outfile=f\"{RESULTS_DIR}/{key}_{metric}.png\",\n",
    "            show=False,\n",
    "            legend=False,\n",
    "            title = title_map[name],\n",
    "        )\n",
    "\n",
    "        if not legend_fig:\n",
    "            regres.plot_metrics_vs_features(\n",
    "                metrics_to_plot, \n",
    "                metric,\n",
    "                labels=['calibration', 'validation'],\n",
    "                name=f\"{key}\",\n",
    "                outfile=f\"{RESULTS_DIR}/{key}_{metric}_with_legend.png\",\n",
    "                show=False,\n",
    "                legend_loc=(0.7,0.6)\n",
    "            )\n",
    "            legend_fig=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_lookup = {\n",
    "    'domain_count': 'Post domain count',\n",
    "    'author_all_activity_count': 'Author activity count',\n",
    "    'mean_author_sentiment_magnitude': 'Author mean sentiment magnitude',\n",
    "    'mean_author_sentiment_sign': 'Author mean sentiment sign',\n",
    "    'mean_author_score': 'Author mean score',\n",
    "    'domain_pagerank': 'Post domain PageRank',\n",
    "    'activity_ratio': 'Author activity ratio',\n",
    "    'time_in_secs': 'Time of day',\n",
    "    'sentiment_sign': 'Post sentiment sign',\n",
    "    'sentiment_magnitude': 'Post sentiment magnitude',\n",
    "    'num_dayofweek': 'Day of week',\n",
    "    'weekday': 'Weekend',\n",
    "    'time_of_day': 'Time of Day',\n",
    "    'external_domain': 'External domain'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dates to csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving dates to csv\")\n",
    "# output dates\n",
    "dates_df = pd.DataFrame.from_dict(dates, orient='index')\n",
    "\n",
    "# output thread counts\n",
    "thread_count_df = (pd.DataFrame.from_dict(modelled_thread_counts_dict, orient='index').T).sort_values(by=['subreddit', 'model window', 'collection window', 'thread size threshold'])\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(f'{RESULTS_DIR}/dataset_info.xlsx') as writer:\n",
    "    dates_df.to_excel(writer, sheet_name='dates')\n",
    "    thread_count_df.to_excel(writer, sheet_name='sizes', index=False)\n",
    "    for subreddit in features_dict:\n",
    "        df = pd.DataFrame.from_dict(features_dict[subreddit])\n",
    "        df.replace(feature_name_lookup, inplace=True)\n",
    "        df = df.reset_index(names='feature')\n",
    "        df['feature'] = df.feature + 1\n",
    "        df.to_excel(writer, sheet_name=f'{subreddit}_feats', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
